{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y1onB6kUvo4Z"
      },
      "outputs": [],
      "source": [
        "# import libraries (you may add additional imports but you may not have to)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iAQGqqO_vo4d",
        "outputId": "c29df3a3-32ea-46f9-cb83-87533b64adb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-20 21:02:14--  https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.2.33, 104.26.3.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26085508 (25M) [application/zip]\n",
            "Saving to: â€˜book-crossings.zipâ€™\n",
            "\n",
            "book-crossings.zip  100%[===================>]  24.88M  58.1MB/s    in 0.4s    \n",
            "\n",
            "2024-07-20 21:02:15 (58.1 MB/s) - â€˜book-crossings.zipâ€™ saved [26085508/26085508]\n",
            "\n",
            "Archive:  book-crossings.zip\n",
            "  inflating: BX-Book-Ratings.csv     \n",
            "  inflating: BX-Books.csv            \n",
            "  inflating: BX-Users.csv            \n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NClILWOiEd6Q"
      },
      "outputs": [],
      "source": [
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xAcXjkCFCh0A",
        "outputId": "efbefb58-212d-476d-8c0b-cfb2ac8bbcba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and removed 20,175 duplicate copies of books and 0 duplicate copies of ratings\n",
            "Removed 250,596 rows (99.76%) of books with less than 100 reviews\n",
            "Removed 1,146,574 rows (99.72%) of user ratings with less than 200 reviews per account or invalid books\n"
          ]
        }
      ],
      "source": [
        "# add your code here - consider creating a new cell for each section of code\n",
        "# CLEAN UP THE DATA\n",
        "\n",
        "duplicate_books = df_books.groupby(['title', 'author']).title.agg(['count']).reset_index().query('count > 1')\n",
        "duplicates_books_count = duplicate_books['count'].sum() - len(duplicate_books)\n",
        "\n",
        "duplicate_ratings = df_ratings.groupby(['isbn', 'user']).isbn.agg(['count']).reset_index().query('count > 1')\n",
        "duplicates_ratings_count = duplicate_ratings['count'].sum() - len(duplicate_ratings)\n",
        "\n",
        "## Modify the DF to drop duplicate or irrelevant rows\n",
        "df_books = df_books.drop_duplicates(subset=['title', 'author'])\n",
        "df_ratings = df_ratings.drop_duplicates(subset=['isbn', 'user'])\n",
        "\n",
        "print(\"Found and removed {:,} duplicate copies of books and {:,} duplicate copies of ratings\".format(duplicates_books_count, duplicates_ratings_count))\n",
        "\n",
        "## Books\n",
        "books_count_before = len(df_books)\n",
        "books_with_ratings = df_books.merge(df_ratings, on='isbn')\n",
        "grouped_by_isbn = books_with_ratings.groupby(['isbn', 'title']).rating.agg(['count', 'mean']).reset_index()\n",
        "books_min_count = 100\n",
        "acceptable_books = grouped_by_isbn.query('count >= {}'.format(books_min_count))['isbn'].tolist()\n",
        "grouped_by_isbn = grouped_by_isbn[grouped_by_isbn['isbn'].isin(acceptable_books)]\n",
        "df_books = df_books[df_books['isbn'].isin(acceptable_books)]\n",
        "books_count_after = len(df_books)\n",
        "b_percent_change = round((books_count_before-books_count_after)/books_count_before*100, 2)\n",
        "print('Removed {:,} rows ({}%) of books with less than {} reviews'.format(books_count_before - books_count_after, b_percent_change, books_min_count))\n",
        "\n",
        "## Users\n",
        "users_count_before = len(df_ratings)\n",
        "ratings_min_count = 200;\n",
        "df_ratings = df_ratings[df_ratings['isbn'].isin(acceptable_books)]\n",
        "acceptable_users = df_ratings.groupby(['user']).rating.agg(['count']).reset_index().query('count >= {}'.format(ratings_min_count))['user'].tolist()\n",
        "df_ratings = df_ratings[df_ratings['user'].isin(acceptable_users)]\n",
        "users_count_after = len(df_ratings)\n",
        "u_percent_change = round((users_count_before-users_count_after)/users_count_before*100,2)\n",
        "print('Removed {:,} rows ({}%) of user ratings with less than {} reviews per account or invalid books'.format(users_count_before - users_count_after, u_percent_change, ratings_min_count))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORMAT THE LAST DATA BEFORE CREATING MODAL\n",
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})\n",
        "\n",
        "df = df_ratings\n",
        "counts1 = df['user'].value_counts()\n",
        "counts2 = df['isbn'].value_counts()\n",
        "\n",
        "df = df[~df['user'].isin(counts1[counts1 < 200].index)]\n",
        "df = df[~df['isbn'].isin(counts2[counts2 < 100].index)]\n",
        "\n",
        "\n",
        "merged_df = pd.merge(right=df, left = df_books, on=\"isbn\")\n",
        "merged_df = merged_df.drop_duplicates(subset=[\"title\", \"user\"])\n",
        "\n",
        "books_features_pivot = merged_df.pivot(\n",
        "  index='title',\n",
        "  columns='user',\n",
        "  values='rating'\n",
        ").fillna(0)\n",
        "\n",
        "mat_books_features = csr_matrix(books_features_pivot.values)"
      ],
      "metadata": {
        "id": "VAvy5BAW9HAG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f5ZUd-L1SQz7"
      },
      "outputs": [],
      "source": [
        "# function to return recommended books - this will be tested\n",
        "## function to return recommended books - this will be tested\n",
        "def get_recommends(book = \"\", n = 5):\n",
        "  \"\"\"\n",
        "  make top n books recommendations\n",
        "  Parameters\n",
        "  ----------\n",
        "  book: str, name of user input book\n",
        "  n: int, top n recommendations\n",
        "  \"\"\"\n",
        "  # Prepare for model\n",
        "  pivot = books_features_pivot\n",
        "  titles = list(pivot.index.values)\n",
        "  data = pivot.values\n",
        "\n",
        "  def title_2_index(title):\n",
        "    ind = titles.index(title)\n",
        "    return data[ind,:]\n",
        "\n",
        "  def index_2_title(ind):\n",
        "    return titles[ind]\n",
        "\n",
        "\n",
        "  # Build model\n",
        "  model = NearestNeighbors(metric=\"cosine\",algorithm=\"brute\", p=2)\n",
        "  model.fit(data)\n",
        "\n",
        "  # Run model to get recommendations\n",
        "  idx = title_2_index(book)\n",
        "  distances, indices = model.kneighbors(\n",
        "    np.reshape(idx,[1,-1]),\n",
        "    n_neighbors=n+1\n",
        "  )\n",
        "\n",
        "  raw_recommends = sorted(\n",
        "    list(\n",
        "      zip(\n",
        "        indices.squeeze().tolist(),\n",
        "        distances.squeeze().tolist()\n",
        "      )\n",
        "    ),\n",
        "    key=lambda x: x[1]\n",
        "  )[1:]\n",
        "\n",
        "  # print results\n",
        "  recommended_books = []\n",
        "  print('Recommendations for {}:'.format(book))\n",
        "  for i, (idx, dist) in enumerate(raw_recommends):\n",
        "      dist = dist\n",
        "      recommended_books.append([index_2_title(idx), dist])\n",
        "      print('{0}: {1}, with distance of {2:,.2f}'.format(i+1, index_2_title(idx), dist))\n",
        "  print('-----------------')\n",
        "  return [book, recommended_books]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\", 10)\n",
        "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True', 'The Lovely Bones: A Novel']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77, 0.72]\n",
        "  recommended_books.reverse()\n",
        "  recommended_books_dist.reverse()\n",
        "\n",
        "  for i in range(2):\n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()"
      ],
      "metadata": {
        "id": "O5lL4cJS8MlU",
        "outputId": "9fee83e4-b4a1-4e03-b8d8-1def25e1ae75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for Where the Heart Is (Oprah's Book Club (Paperback)):\n",
            "1: The Lovely Bones: A Novel, with distance of 0.72\n",
            "2: I Know This Much Is True, with distance of 0.77\n",
            "3: The Surgeon, with distance of 0.77\n",
            "4: The Weight of Water, with distance of 0.77\n",
            "5: I'll Be Seeing You, with distance of 0.80\n",
            "6: The Dive From Clausen's Pier (Alex Awards), with distance of 0.80\n",
            "7: Tis: A Memoir, with distance of 0.81\n",
            "8: Icy Sparks, with distance of 0.81\n",
            "9: Unspeakable, with distance of 0.81\n",
            "10: What Looks Like Crazy On An Ordinary Day, with distance of 0.82\n",
            "-----------------\n",
            "You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_book_recommendation_knn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}